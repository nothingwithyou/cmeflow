{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355fc33b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import *\n",
    "\n",
    "from gmflow.gmflow import GMFlow\n",
    "from gmflow.loss import flow_loss_func\n",
    "from gmflow.liteflownet import LiteFlowNet\n",
    "from evaluate import inference_on_dir\n",
    "\n",
    "from utils.logger import Logger\n",
    "from utils import misc\n",
    "from data.datasets import build_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22dd375d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parser = get_args_parser()\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bf95c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f692e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.13.1+cu117\n",
      "Namespace(attention_type='swin', attn_splits_list=[2], batch_size=2, checkpoint_dir='tmp', corr_radius_list=[-1], count_time=False, dir_paired_data=False, distributed=False, eval=False, evaluate_matched_unmatched=False, feature_channels=128, ffn_dim_expansion=4, fwd_bwd_consistency_check=False, gamma=0.9, gpu_ids=0, grad_clip=1.0, image_size=[320, 1200], inference_dir=None, inference_size=None, lambda_biflow=1, lambda_photowarp=2, lambda_smooth=1, launcher='none', local_rank=0, lr=0.0001, max_flow=400, no_resume_optimizer=False, no_save_flo=False, num_head=1, num_scales=1, num_steps=100000, num_transformer_layers=6, num_workers=20, output_path='output', padding_factor=16, pred_bidir_flow=False, prop_radius_list=[-1], resume=None, save_ckpt_freq=10000, save_eval_to_file=False, save_flo_flow=False, save_latest_ckpt_freq=1000, save_vis_flow=False, seed=326, sequence_length=6, strict_resume=False, submission=False, summary_freq=100, supervise=False, train_dir='../halo/grad_fits', upsample_factor=8, val_dir='', val_freq=10000, weight_decay=0.0001, with_speed_metric=False)\n"
     ]
    }
   ],
   "source": [
    "if not args.eval and not args.submission and args.inference_dir is None:\n",
    "    if args.local_rank == 0:\n",
    "        print('pytorch version:', torch.__version__)\n",
    "        print(args)\n",
    "        misc.save_args(args)\n",
    "        misc.check_path(args.checkpoint_dir)\n",
    "        misc.save_command(args.checkpoint_dir)\n",
    "\n",
    "seed = args.seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda'\n",
    "# model\n",
    "model = LiteFlowNet(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290c94b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model definition:\n",
      "LiteFlowNet(\n",
      "  (moduleFeatures): Features(\n",
      "    (moduleOne): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (moduleTwo): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): LeakyReLU(negative_slope=0.1)\n",
      "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (moduleThr): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (moduleFou): Sequential(\n",
      "      (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "      (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (moduleFiv): Sequential(\n",
      "      (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (moduleSix): Sequential(\n",
      "      (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "  )\n",
      "  (moduleMatching): ModuleList(\n",
      "    (0): Matching(\n",
      "      (moduleFeat): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
      "      (moduleUpcorr): ConvTranspose2d(49, 49, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=49, bias=False)\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      )\n",
      "    )\n",
      "    (1): Matching(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
      "      (moduleUpcorr): ConvTranspose2d(49, 49, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=49, bias=False)\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (2): Matching(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (3): Matching(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): Matching(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (moduleSubpixel): ModuleList(\n",
      "    (0): Subpixel(\n",
      "      (moduleFeat): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(130, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      )\n",
      "    )\n",
      "    (1): Subpixel(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(130, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (2): Subpixel(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(194, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (3): Subpixel(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): Subpixel(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(386, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (moduleRegularization): ModuleList(\n",
      "    (0): Regularization(\n",
      "      (moduleFeat): Sequential(\n",
      "        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): LeakyReLU(negative_slope=0.1)\n",
      "        (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): LeakyReLU(negative_slope=0.1)\n",
      "        (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleDist): Sequential(\n",
      "        (0): Conv2d(32, 49, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n",
      "        (1): Conv2d(49, 49, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
      "      )\n",
      "      (moduleScaleX): Conv2d(49, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (moduleScaleY): Conv2d(49, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Regularization(\n",
      "      (moduleFeat): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): LeakyReLU(negative_slope=0.1)\n",
      "        (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): LeakyReLU(negative_slope=0.1)\n",
      "        (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleDist): Sequential(\n",
      "        (0): Conv2d(32, 25, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "        (1): Conv2d(25, 25, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "      )\n",
      "      (moduleScaleX): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (moduleScaleY): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Regularization(\n",
      "      (moduleFeat): Sequential(\n",
      "        (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): LeakyReLU(negative_slope=0.1)\n",
      "        (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): LeakyReLU(negative_slope=0.1)\n",
      "        (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleDist): Sequential(\n",
      "        (0): Conv2d(32, 25, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "        (1): Conv2d(25, 25, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "      )\n",
      "      (moduleScaleX): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (moduleScaleY): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Regularization(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): LeakyReLU(negative_slope=0.1)\n",
      "        (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): LeakyReLU(negative_slope=0.1)\n",
      "        (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleDist): Sequential(\n",
      "        (0): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (moduleScaleX): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (moduleScaleY): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Regularization(\n",
      "      (moduleFeat): Sequential()\n",
      "      (moduleMain): Sequential(\n",
      "        (0): Conv2d(195, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1)\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.1)\n",
      "        (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.1)\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): LeakyReLU(negative_slope=0.1)\n",
      "        (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): LeakyReLU(negative_slope=0.1)\n",
      "        (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (moduleDist): Sequential(\n",
      "        (0): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (moduleScaleX): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (moduleScaleY): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Use 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "if not args.eval and not args.submission and not args.inference_dir:\n",
    "    print('Model definition:')\n",
    "    print(model)\n",
    "\n",
    "    print('Use %d GPUs' % torch.cuda.device_count())\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model_without_ddp = model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1f23c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 5381969\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print('Number of params:', num_params)\n",
    "if not args.eval and not args.submission and args.inference_dir is None:\n",
    "    save_name = '%d_parameters' % num_params\n",
    "    open(os.path.join(args.checkpoint_dir, save_name), 'a').close()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_without_ddp.parameters(), lr=args.lr,\n",
    "                              weight_decay=args.weight_decay)\n",
    "\n",
    "start_step = 0\n",
    "# resume checkpoints\n",
    "if args.resume:\n",
    "    print('Load checkpoint: %s' % args.resume)\n",
    "\n",
    "    loc = 'cuda:{}'.format(args.local_rank)\n",
    "    checkpoint = torch.load(args.resume, map_location=loc)\n",
    "\n",
    "    weights = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "\n",
    "    model_without_ddp.load_state_dict(weights, strict=args.strict_resume)\n",
    "\n",
    "    if 'optimizer' in checkpoint and 'step' in checkpoint and 'epoch' in checkpoint and not \\\n",
    "            args.no_resume_optimizer:\n",
    "        print('Load optimizer')\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_step = checkpoint['step']\n",
    "\n",
    "    print(' start_step: %d' % (start_step))\n",
    "\n",
    "# evaluate\n",
    "\n",
    "# inferece on a dir\n",
    "if args.inference_dir is not None:\n",
    "    inference_on_dir(model_without_ddp,\n",
    "                     inference_dir=args.inference_dir,\n",
    "                     output_path=args.output_path,\n",
    "                     padding_factor=args.padding_factor,\n",
    "                     inference_size=args.inference_size,\n",
    "                     paired_data=args.dir_paired_data,\n",
    "                     save_flo_flow=args.save_flo_flow,\n",
    "                     attn_splits_list=args.attn_splits_list,\n",
    "                     corr_radius_list=args.corr_radius_list,\n",
    "                     prop_radius_list=args.prop_radius_list,\n",
    "                     pred_bidir_flow=args.pred_bidir_flow,\n",
    "                     fwd_bwd_consistency_check=args.fwd_bwd_consistency_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7582afc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 1925\n"
     ]
    }
   ],
   "source": [
    "train_dataset = build_train_dataset(args)\n",
    "print('Number of training images:', len(train_dataset))\n",
    "\n",
    "# Multi-processing\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size,\n",
    "                                           shuffle=True, num_workers=args.num_workers,\n",
    "                                           pin_memory=True, drop_last=True)\n",
    "\n",
    "last_epoch = start_step if args.resume and start_step > 0 else -1\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, args.lr,\n",
    "    args.num_steps + 10,\n",
    "    pct_start=0.05,\n",
    "    cycle_momentum=False,\n",
    "    anneal_strategy='cos',\n",
    "    last_epoch=last_epoch,\n",
    ")\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    summary_writer = SummaryWriter(args.checkpoint_dir)\n",
    "    logger = Logger(lr_scheduler, summary_writer, args.summary_freq,\n",
    "                    start_step=start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673c0fdc",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    }
   ],
   "source": [
    "fetch = iter(train_loader)\n",
    "model.train()\n",
    "print('Start training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f59b9773",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = next(fetch)\n",
    "# mannual change random seed for shuffling every epoch\n",
    "img1, img2 = inputs['img1'].to(device), inputs['img2'].to(device)\n",
    "flow_name = inputs['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d653e73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1440, 327])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2[:, 0, ::].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e6f4fd",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cqy/anaconda3/envs/pt/lib/python3.8/site-packages/cupy/cuda/compiler.py:461: UserWarning: cupy.cuda.compile_with_cache has been deprecated in CuPy v10, and will be removed in the future. Use cupy.RawModule or cupy.RawKernel instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 47.54 GiB total capacity; 46.93 GiB already allocated; 5.56 MiB free; 47.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m seq \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(args\u001B[38;5;241m.\u001B[39msequence_length):\n\u001B[0;32m----> 4\u001B[0m     sout, sloss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg1\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg2\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     out\u001B[38;5;241m.\u001B[39mappend(sout)\n\u001B[1;32m      6\u001B[0m     loss\u001B[38;5;241m.\u001B[39mappend(sloss)\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:169\u001B[0m, in \u001B[0;36mDataParallel.forward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m ({},)\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_ids) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 169\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m replicas \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplicate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_ids[:\u001B[38;5;28mlen\u001B[39m(inputs)])\n\u001B[1;32m    171\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/data/fits/gmflow-main/gmflow/liteflownet.py:602\u001B[0m, in \u001B[0;36mLiteFlowNet.forward\u001B[0;34m(self, img1, img2, label)\u001B[0m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39msupervise:\n\u001B[1;32m    601\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ed_multiscale_supervised_error(forward_flow_collection, label\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice), args\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs)\n\u001B[0;32m--> 602\u001B[0m backward_flow_collection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mone_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43msecond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfirst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    603\u001B[0m flow_full_reso \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprossing_flow(flow_collection\u001B[38;5;241m=\u001B[39mbackward_flow_collection,\n\u001B[1;32m    604\u001B[0m                                         raw_shape\u001B[38;5;241m=\u001B[39m(h, w),\n\u001B[1;32m    605\u001B[0m                                         processed_shape\u001B[38;5;241m=\u001B[39m(p_h, p_w))\n\u001B[1;32m    606\u001B[0m backward_flow_collection\u001B[38;5;241m.\u001B[39mappend(flow_full_reso)\n",
      "File \u001B[0;32m/data/fits/gmflow-main/gmflow/liteflownet.py:535\u001B[0m, in \u001B[0;36mLiteFlowNet.one_pass\u001B[0;34m(self, first, second)\u001B[0m\n\u001B[1;32m    527\u001B[0m     tensorFlow \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmoduleMatching[intLevel](\n\u001B[1;32m    528\u001B[0m         tensorFirst[intLevel], tensorSecond[intLevel],\n\u001B[1;32m    529\u001B[0m         tensorFeaturesFirst[intLevel], tensorFeaturesSecond[intLevel],\n\u001B[1;32m    530\u001B[0m         tensorFlow)\n\u001B[1;32m    531\u001B[0m     tensorFlow \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmoduleSubpixel[intLevel](\n\u001B[1;32m    532\u001B[0m         tensorFirst[intLevel], tensorSecond[intLevel],\n\u001B[1;32m    533\u001B[0m         tensorFeaturesFirst[intLevel], tensorFeaturesSecond[intLevel],\n\u001B[1;32m    534\u001B[0m         tensorFlow)\n\u001B[0;32m--> 535\u001B[0m     tensorFlow \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmoduleRegularization\u001B[49m\u001B[43m[\u001B[49m\u001B[43mintLevel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtensorFirst\u001B[49m\u001B[43m[\u001B[49m\u001B[43mintLevel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorSecond\u001B[49m\u001B[43m[\u001B[49m\u001B[43mintLevel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtensorFeaturesFirst\u001B[49m\u001B[43m[\u001B[49m\u001B[43mintLevel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorFeaturesSecond\u001B[49m\u001B[43m[\u001B[49m\u001B[43mintLevel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtensorFlow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    539\u001B[0m     flow_collection\u001B[38;5;241m.\u001B[39mappend(tensorFlow)\n\u001B[1;32m    541\u001B[0m flow_collection[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4.0\u001B[39m  \u001B[38;5;66;03m# Final flow scale 20.0, others 5.0\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/data/fits/gmflow-main/gmflow/liteflownet.py:456\u001B[0m, in \u001B[0;36mLiteFlowNet.__init__.<locals>.Regularization.forward\u001B[0;34m(self, tensorFirst, tensorSecond, tensorFeaturesFirst, tensorFeaturesSecond, tensorFlow)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensorFirst, tensorSecond, tensorFeaturesFirst,\n\u001B[1;32m    449\u001B[0m             tensorFeaturesSecond, tensorFlow):\n\u001B[1;32m    450\u001B[0m     tensorDifference \u001B[38;5;241m=\u001B[39m (tensorFirst \u001B[38;5;241m-\u001B[39m Backward(\n\u001B[1;32m    451\u001B[0m         tensorInput\u001B[38;5;241m=\u001B[39mtensorSecond,\n\u001B[1;32m    452\u001B[0m         tensorFlow\u001B[38;5;241m=\u001B[39mtensorFlow \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdblBackward))\u001B[38;5;241m.\u001B[39mpow(\u001B[38;5;241m2.0\u001B[39m)\u001B[38;5;241m.\u001B[39msum(\n\u001B[1;32m    453\u001B[0m             \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39msqrt()\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[1;32m    455\u001B[0m     tensorDist \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmoduleDist(\n\u001B[0;32m--> 456\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmoduleMain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtensorDifference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorFlow\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\n\u001B[1;32m    459\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtensorFlow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensorFlow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensorFlow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmoduleFeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensorFeaturesFirst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m            \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    463\u001B[0m     tensorDist \u001B[38;5;241m=\u001B[39m tensorDist\u001B[38;5;241m.\u001B[39mpow(\u001B[38;5;241m2.0\u001B[39m)\u001B[38;5;241m.\u001B[39mneg()\n\u001B[1;32m    464\u001B[0m     tensorDist \u001B[38;5;241m=\u001B[39m (tensorDist \u001B[38;5;241m-\u001B[39m tensorDist\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39mexp()\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 47.54 GiB total capacity; 46.93 GiB already allocated; 5.56 MiB free; 47.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "loss = []\n",
    "for seq in range(args.sequence_length):\n",
    "    sout, sloss = model(img1[:, seq, ::], img2[:, seq, ::])\n",
    "    out.append(sout)\n",
    "    loss.append(sloss)\n",
    "loss = torch.sum(torch.cat(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393c8698",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d10ff1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgmflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mGMflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GMFlow\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgmflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloss\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m flow_loss_func\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgmflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mliteflownet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LiteFlowNet\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mevaluate\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m inference_on_dir\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlogger\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Logger\n",
      "File \u001B[0;32m/data/fits/gmflow-main/gmflow/liteflownet.py:7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcorrelation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FunctionCorrelation  \u001B[38;5;66;03m# the custom cost volume layer\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dict, List, Tuple\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tensor, nn\n",
      "File \u001B[0;32m/data/fits/gmflow-main/gmflow/correlation.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcupy\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import *\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "\n",
    "from gmflow.GMflow import GMFlow\n",
    "from gmflow.loss import flow_loss_func\n",
    "from gmflow.liteflownet import LiteFlowNet\n",
    "from evaluate import inference_on_dir\n",
    "\n",
    "from utils.logger import Logger\n",
    "from utils import misc\n",
    "from data.datasets import build_train_dataset\n",
    "from glob import glob\n",
    "from utils.flow_viz import flow_to_image\n",
    "from torchvision import transforms\n",
    "from main import get_args_parser\n",
    "from utils.flow_viz import save_vis_flow_tofile\n",
    "from PIL import Image\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1cb90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parser = get_args_parser()\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28586ed2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046b923d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = GMFlow(feature_channels=args.feature_channels,\n",
    "                   num_scales=args.num_scales,\n",
    "                   upsample_factor=args.upsample_factor,\n",
    "                   num_head=args.num_head,\n",
    "                   attention_type=args.attention_type,\n",
    "                   ffn_dim_expansion=args.ffn_dim_expansion,\n",
    "                   num_transformer_layers=args.num_transformer_layers,\n",
    "                   ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ee8f21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LiteFlowNet(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f8c1e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('tmp-1/checkpoint_latest.pth')\n",
    "weights = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e87a99c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def channel_norm(img):\n",
    "    datamax = [7979]\n",
    "    datamin = [980]\n",
    "    for i in range(len(datamax)):\n",
    "        img[i] = (img[i] - datamin[i]) / (datamax[i] - datamin[i])\n",
    "    return img\n",
    "\n",
    "img_trans = transforms.Compose([\n",
    "        # rand_crop,\n",
    "        transforms.Resize(args.image_size, antialias=True),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca1c8cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = sorted(glob('halo/halo55/22584696/*.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb99d8da",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m         img1 \u001B[38;5;241m=\u001B[39m img1\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     15\u001B[0m         img2 \u001B[38;5;241m=\u001B[39m img2\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m         outs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m#         outs = np.minimum(outs[0].cpu(), np.percentile(outs[0].cpu(), 99))\u001B[39;00m\n\u001B[1;32m     18\u001B[0m         outs \u001B[38;5;241m=\u001B[39m outs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\n",
      "File \u001B[0;32m~/anaconda3/envs/pt2/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/data/fits/gmflow-main/gmflow/GMflow.py:109\u001B[0m, in \u001B[0;36mGMFlow.forward\u001B[0;34m(self, img0, img1, attn_splits_list, corr_radius_list, prop_radius_list, pred_bidir_flow, **kwargs)\u001B[0m\n\u001B[1;32m    105\u001B[0m feature0_list, feature1_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextract_feature(img0, img1)  \u001B[38;5;66;03m# list of features\u001B[39;00m\n\u001B[1;32m    107\u001B[0m flow \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 109\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mattn_splits_list\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(corr_radius_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(prop_radius_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_scales\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m scale_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_scales):\n\u001B[1;32m    112\u001B[0m     feature0, feature1 \u001B[38;5;241m=\u001B[39m feature0_list[scale_idx], feature1_list[scale_idx]\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(a)-1):\n",
    "        img1_path = a[i]\n",
    "        img2_path = a[i+1]\n",
    "        s1 = torch.FloatTensor(torch.load(img1_path))\n",
    "        s2 = torch.FloatTensor(torch.load(img2_path))\n",
    "        s1 = channel_norm(s1)\n",
    "        s2 = channel_norm(s2)\n",
    "        s1 = torch.unsqueeze(s1[:, 7:], dim=0)\n",
    "        s2 = torch.unsqueeze(s2[:, 7:], dim=0)\n",
    "        img1 = img_trans(s1)\n",
    "        img2 = img_trans(s2)\n",
    "        img1 = img1.unsqueeze(0)\n",
    "        img2 = img2.unsqueeze(0)\n",
    "        outs = model(img1.to('cuda'), img2.to('cuda'))\n",
    "#         outs = np.minimum(outs[0].cpu(), np.percentile(outs[0].cpu(), 99))\n",
    "        outs = outs[0].cpu()\n",
    "        flow_pred = flow_tensor_to_image(outs)\n",
    "        img = Image.fromarray(np.transpose(flow, (1,2,0)))\n",
    "        img.save('img_flow/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a47e8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#gmflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f80967c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cqy/anaconda3/envs/pt2/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#gmflow\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(a)-1):\n",
    "        img1_path = a[i]\n",
    "        img2_path = a[i+1]\n",
    "        s1 = torch.FloatTensor(torch.load(img1_path))\n",
    "        s2 = torch.FloatTensor(torch.load(img2_path))\n",
    "        s1 = channel_norm(s1)\n",
    "        s2 = channel_norm(s2)\n",
    "        s1 = torch.unsqueeze(s1[:, 7:], dim=0)\n",
    "        s2 = torch.unsqueeze(s2[:, 7:], dim=0)\n",
    "        img1 = img_trans(s1)\n",
    "        img2 = img_trans(s2)\n",
    "        img1 = img1.unsqueeze(0)\n",
    "        img2 = img2.unsqueeze(0)\n",
    "        a1 = model(img1.to('cuda'), img2.to('cuda'),\n",
    "               attn_splits_list=args.attn_splits_list,\n",
    "               corr_radius_list=args.corr_radius_list,\n",
    "               prop_radius_list=args.prop_radius_list, )\n",
    "        outs = a1['flow_preds']\n",
    "        flow = outs[0][0].cpu()\n",
    "        flow = flow.permute(1, 2, 0)\n",
    "        flow = flow.detach().cpu().numpy()\n",
    "        flow = np.maximum(flow, np.percentile(flow, 0.01))\n",
    "        flow = np.minimum(flow,np.percentile(flow, 99.9))\n",
    "        flow = cv.GaussianBlur(flow,(5,5),0)\n",
    "        color = flow_to_image(flow)\n",
    "        img = Image.fromarray(color)\n",
    "        img.save('img_flow/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d54322e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fetch = iter(train_loader)\n",
    "for i in range(len(train_dataset)):\n",
    "    inputs = next(fetch)\n",
    "    img1, img2 = inputs['img1'].permute(1, 0, 2, 3, 4).contiguous(), inputs['img2'].permute(1, 0, 2, 3, 4).contiguous()\n",
    "    if torch.isnan(img1).any() or torch.isnan(img2).any():\n",
    "        print('have none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879a19c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}